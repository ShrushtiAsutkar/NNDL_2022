{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_RNN_LSTM_(milk_production_prediction).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfv2H5ue39vtsVwYvaIAZG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShrushtiAsutkar/NNDL_2022/blob/master/6_RNN_LSTM_(milk_production_prediction).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN Model using LSTM to prediction milk production."
      ],
      "metadata": {
        "id": "wdVsCJMA_wWJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvPVQKbn_ldC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/monthly-milk-production-pounds.csv',index_col='Month',parse_dates=True)"
      ],
      "metadata": {
        "id": "tpFoVvYR5Veq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying month wise production data\n",
        "df.index.freq='MS'"
      ],
      "metadata": {
        "id": "eAzJ_Udj5YoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "FZHnUOob_umR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying Data in Plot format\n",
        "df.plot(figsize=(15,8))"
      ],
      "metadata": {
        "id": "vS1cwfqb_ydp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose"
      ],
      "metadata": {
        "id": "AQP9RzVu_0LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#will show seperate graph for trend of production, seasonal changes observered and overall obseravation(same as above graph)\n",
        "#The residual graph shows Overall - trend - seasonal, we can call it as noise and cannot we determined.\n",
        "results = seasonal_decompose(df['Monthly milk production (pounds per cow)'])"
      ],
      "metadata": {
        "id": "_-C-3PXo_1pC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.plot();"
      ],
      "metadata": {
        "id": "OWCrzPj9_3Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "761ppVVJ_5AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = df.iloc[:156]        # all data except the last 12 months data 168-12=156 to train the model.\n",
        "test = df.iloc[156:]         # Last 12 months data used as testing set."
      ],
      "metadata": {
        "id": "wCgJn6VO_6e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "-lSd7T3L_9CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#magnitude of the production values not in proper range\n",
        "df.head(),df.tail()"
      ],
      "metadata": {
        "id": "BjnNzj-c_-wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.fit(train)\n",
        "scaled_train = scaler.transform(train)\n",
        "scaled_test = scaler.transform(test)"
      ],
      "metadata": {
        "id": "BynztJHYAAV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_train[:10]"
      ],
      "metadata": {
        "id": "cn3R_tOXABj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import TimeseriesGenerator"
      ],
      "metadata": {
        "id": "ngWnU-WpAC-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define generator\n",
        "n_input = 3\n",
        "n_features = 1\n",
        "generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)\n",
        "#predicting 4th output using first three inputs\n",
        "X,y = generator[0]\n",
        "print(f'Given the Array: \\n{X.flatten()}')\n",
        "print(f'Predict this y: \\n {y}')"
      ],
      "metadata": {
        "id": "1m5CeX1OAFlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting 4th output using first three inputs\n",
        "X,y = generator[1]\n",
        "print(f'Given the Array: \\n{X.flatten()}')\n",
        "print(f'Predict this y: \\n {y}')"
      ],
      "metadata": {
        "id": "JZBKuL7kAHMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 row 3 columns and 1 feature\n",
        "X.shape"
      ],
      "metadata": {
        "id": "c424mXhJAIbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We do the same thing, but now instead for 12 months\n",
        "n_input = 12\n",
        "generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "# define model\n",
        "model = Sequential()   #layers are in sequence i.e one after the another\n",
        "model.add(LSTM(100, activation='relu', input_shape=(n_input, n_features)))   #100 neurons and ReLU activation function \n",
        "model.add(Dense(1))    #output layer\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "R2nLi0IKAKXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "model.fit(generator,epochs=50)  #generator creates batches of 3-3 inputs and using that predict the next value"
      ],
      "metadata": {
        "id": "BVnLwMxrAMfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_per_epoch = model.history.history['loss']\n",
        "plt.plot(range(len(loss_per_epoch)),loss_per_epoch)\n",
        "#we can obsreve the decrease in loss fro the graph over 50 epoch"
      ],
      "metadata": {
        "id": "K8fWNg1mAO35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#taking last 12 months values in training set to make prediction for 1st value in test set\n",
        "last_train_batch = scaled_train[-12:]\n",
        "#reshaping data in 1, 3, 1 i.e 1, no. of input, no. of features\n",
        "last_train_batch = last_train_batch.reshape((1, n_input, n_features))\n",
        "model.predict(last_train_batch)"
      ],
      "metadata": {
        "id": "-_rvPnZOARAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_test[0]     #original- 0.61  predicted- 0.67  difference is negligible"
      ],
      "metadata": {
        "id": "2i0Th9W4AS5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#empty list of test predictions\n",
        "test_predictions = []     \n",
        "first_eval_batch = scaled_train[-n_input:]      #last 12 values from the training set\n",
        "current_batch = first_eval_batch.reshape((1, n_input, n_features))   #reshaping this last 12 values\n",
        "\n",
        "for i in range(len(test)):\n",
        "    \n",
        "    # get the prediction value for the first batch\n",
        "    current_pred = model.predict(current_batch)[0]\n",
        "    \n",
        "    # append the prediction into the array\n",
        "    test_predictions.append(current_pred) \n",
        "    \n",
        "    # use the prediction to update the batch and remove the first value\n",
        "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"
      ],
      "metadata": {
        "id": "-UVGYt_2AUjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions"
      ],
      "metadata": {
        "id": "9iSBhtthAVtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#changing back to original scale.\n",
        "test.head()"
      ],
      "metadata": {
        "id": "1QB3Yr27AXQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_predictions = scaler.inverse_transform(test_predictions)\n",
        "test['Predictions'] = true_predictions"
      ],
      "metadata": {
        "id": "vXgDuVW9AYeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Developed model is not 100% accurate, but is quite close \n",
        "test.plot(figsize=(15,8))"
      ],
      "metadata": {
        "id": "N0jRZi3JAZ1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "rmse=sqrt(mean_squared_error(test['Monthly milk production (pounds per cow)'],test['Predictions']))\n",
        "print(rmse)\n",
        "#displays root mean square error."
      ],
      "metadata": {
        "id": "givC1tmmAbXZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}